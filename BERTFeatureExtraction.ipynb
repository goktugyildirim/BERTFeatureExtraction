{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 50, 768)\n"
     ]
    }
   ],
   "source": [
    "input = \"Love is between girl and boy. Love is so fantastic. Engineers are very kind people. Engineers are sad.\"\n",
    "\n",
    "def BERTFeatureExtraction(input, max_token_size):\n",
    "    input = input.split(\".\")\n",
    "    input = input[:-1]\n",
    "    \n",
    "    \n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    import torch\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    features = []\n",
    "    \n",
    "    for sentence in (input):\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        special_tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        padded_tokens = special_tokens + ['[PAD]' for i in range(max_token_size-len(special_tokens))]\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in padded_tokens]\n",
    "        \n",
    "        token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "        attn_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
    "        \n",
    "        hidden_repr, cls_head = model(token_ids, attention_mask = attn_mask)     \n",
    "        features.append(hidden_repr[0]) #batch dimension reduction (1, token_size, wv) => (token_size, wv)\n",
    "    \n",
    "    import numpy as np\n",
    "    features = [value.detach().numpy() for value in features]\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "max_token_size = 50\n",
    "\n",
    "features = BERTFeatureExtraction(input, max_token_size) #input is string, output is (batch_size=num_sen, token_size, hidden_dim)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power of the BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "features = features.reshape((4,50*768))\n",
    "\n",
    "model = KMeans(n_clusters=2)\n",
    "labels = model.fit_predict(features)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
